import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import re
import random
import asyncio
from typing import Optional

# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì •ì˜
base_prompt = """
ë‹¹ì‹ ì€ ë¬¸ì¥ ë³€í™˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë¬¸ì¥ì„ ì§€ì •ëœ ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
ë³€í™˜ëœ ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
ì½”ë“œ ë¸”ë¡ì´ë‚˜ ë”°ì˜´í‘œ ì—†ì´ ìˆœìˆ˜í•œ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

# ìŠ¤íƒ€ì¼ë³„ ì§€ì¹¨ ì •ì˜
style_instructions = {
    'formal': "ê²©ì‹ìˆê³  ê³µì‹ì ì¸ ì–´íˆ¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.",
    'casual': "ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ì–´íˆ¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.",
    'polite': "ë§¤ìš° ê³µì†í•˜ê³  ì˜ˆì˜ë°”ë¥¸ ì–´íˆ¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.",
    'cute': "ê·€ì—½ê³  ì• êµìˆëŠ” ì–´íˆ¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”."
}

class TestHandler:
    def __init__(self):
        print("=== HuggingFace ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘ ===")
        self.model_name = "Qwen/Qwen1.5-1.8B"
        
        print("1. í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...")
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_name,
            trust_remote_code=True,
            padding_side="left",
        )
        print("âœ“ í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ")
        
        print("2. GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
        torch.cuda.empty_cache()
        print("âœ“ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
        
        print("3. ëª¨ë¸ ë¡œë”© ì¤‘... (1-3ë¶„ ì†Œìš”)")
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            torch_dtype=torch.float16,
            device_map="auto",
            trust_remote_code=True,
        )
        print("âœ“ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        self.model_loaded = True
        self.inference_timeout = 300  # ì¶”ë¡  íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì´ˆ)
        self.emojis = ['ğŸ’•', 'âœ¨', 'ğŸ¥º', 'ğŸ˜Š', 'ğŸ’', 'ğŸŒ¸', 'ğŸ’—', 'ğŸ’–']
        print("=== ì´ˆê¸°í™” ì™„ë£Œ! ì„œë¹„ìŠ¤ ì¤€ë¹„ë¨ ===")

    async def get_completion(self, message: str, style: str) -> Optional[str]:
        if not self.model_loaded:
            print("[ìƒíƒœ] ëª¨ë¸ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None

        try:
            # ìŠ¤íƒ€ì¼ì— í•´ë‹¹í•˜ëŠ” ì§€ì¹¨ ê°€ì ¸ì˜¤ê¸°
            style_instruction = style_instructions.get(style, "")
            if not style_instruction:
                print(f"[ê²½ê³ ] ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¤íƒ€ì¼: {style}. ê¸°ë³¸ ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
                style_instruction = "ì§€ì •ëœ ìŠ¤íƒ€ì¼ì— ë§ê²Œ ë¬¸ì¥ì„ ë³€í™˜í•´ì£¼ì„¸ìš”."

            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""{base_prompt}
                    {style_instruction}

                    ì…ë ¥: "{message}"
                    """

            inputs = self.tokenizer(
                prompt,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=30000
            ).to(self.model.device)

            # ì¶”ë¡  ì‹œê°„ë§Œ íƒ€ì„ì•„ì›ƒ ì ìš©
            print("[ì²˜ë¦¬] ì¶”ë¡  ì‹œì‘...")
            outputs = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: self.model.generate(
                        input_ids=inputs['input_ids'],
                        attention_mask=inputs['attention_mask'],
                        max_new_tokens=50,
                        temperature=0.5,
                        top_p=0.9,
                        do_sample=True
                    )
                ),
                timeout=self.inference_timeout
            )
            print("[ì²˜ë¦¬] ì¶”ë¡  ì™„ë£Œ")

            response = self.tokenizer.decode(
                outputs[0][inputs.input_ids.shape[1]:],
                skip_special_tokens=True
            ).strip()

            # ìŠ¤íƒ€ì¼ë³„ ì¶”ê°€ ë¡œì§ ì ìš©
            response = self.apply_style_logic(response, style)
            return response

        except asyncio.TimeoutError:
            print(f"[íƒ€ì„ì•„ì›ƒ] {self.inference_timeout}ì´ˆ ì´ˆê³¼")
            return None
        except Exception as e:
            print(f"[ì—ëŸ¬] HuggingFace ëª¨ë¸ ì˜¤ë¥˜: {e}")
            return None

    def apply_style_logic(self, response: str, style: str) -> str:
        """ìŠ¤íƒ€ì¼ë³„ ë³€í™˜ ë¡œì§ ì ìš©"""
        if style == "formal":
            response = response.replace("~ì•¼", "~ì…ë‹ˆë‹¤").replace("~ë„¤", "~ì…ë‹ˆë‹¤")
            response += " ê°ì‚¬í•©ë‹ˆë‹¤."

        elif style == "casual":
            response = response.replace("~ì…ë‹ˆë‹¤", "~ì•¼").replace("~í•©ë‹ˆë‹¤", "~í•´")
            response += " ã…ã…"

        elif style == "polite":
            response = response.replace("~ì•¼", "~ì…ë‹ˆë‹¤").replace("~í•´", "~í•˜ì‹œê² ì–´ìš”?")
            response += " ê³ ë§™ìŠµë‹ˆë‹¤."

        elif style == "cute":
            response = response.replace("~ì…ë‹ˆë‹¤", "~ëƒ¥").replace("~í•©ë‹ˆë‹¤", "~ì–Œ")
            emoji_count = random.randint(1, 2)
            selected_emojis = " " + "".join(random.sample(self.emojis, emoji_count))
            response += selected_emojis

        return response
